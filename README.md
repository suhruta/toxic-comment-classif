# Toxic Comment Classification

An attempt to help make the internet a safer place.

This project was carried out as my Capstone Project. Please feel free to view the ipynb file for the source code.

## Abstract
Technology has advanced significantly in the past two decades - from the introduction of email, WiFi, cloud storage, and even sensors tracking our health data every minute. Access to the internet in this day and age can also be considered as essential as electricity - in fact, in 2016, the UN General Assembly declared that “internet access is a human right”. 

Considering it has become such an essential resource, quality of life is affected by the exposure to toxic and malicious messages such as personal attacks, cyberbullies, etc lurking in every corner of the internet. This has led to the requirement (and hence, several attempts) to create an efficient model for predicting and identifying toxic comments, in order to eliminate their presence. The introduction of Kaggle's competition to classify toxic comments into categories brought great interest in the community of Machine Learning and Deep Learning, and has consequently led to active research in the area. 

This work attempts to compare and contrast different classic Machine Learning Algorithm performances (with more traditional methods like Bag-of-words and TF-IDF) with various Neural Network Architectures and Word Embeddings (GloVe, Word2Vec and FastText). This work also studies the performance of data-specific embeddings (as opposed to pre-trained embeddings) i.e, Embeddings trained on the Toxic Comment Corpus obtained from Kaggle's competition.

Kaggle Competition link: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview 

In the chance the ipynb file times out or shows an error, use this link the access my source code: https://nbviewer.org/github/suhruta/toxic-comment-classif/blob/main/Capstone_TCC.ipynb
